{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_openai_request(content: str, model: str = \"string\", temperature: float = 0, max_tokens: int = 0, url: str = \"http://stargate:8000/v1/chat/completions\"):\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            { \"role\": \"user\", \"content\": content }\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    headers = { \"Content-Type\": \"application/json\" }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def process_item(prompt: str):\n",
    "    response = make_openai_request(prompt, \n",
    "                                   model = \"microsoft/Phi-3-mini-4k-instruct\", \n",
    "                                   max_tokens=2048,\n",
    "                                   temperature=1)\n",
    "    return {'prompt': prompt, 'response': response}\n",
    "\n",
    "def process_dataset(dataset_name: str):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    train_data = dataset['test']\n",
    "    results = []\n",
    "    # count = 0\n",
    "    for item in tqdm(train_data, desc=\"Processing prompts\"):\n",
    "        # if count == 5:\n",
    "        #     break\n",
    "        result = process_item(item['prompt'])\n",
    "        results.append(result)\n",
    "       \n",
    "        # count += 1\n",
    "        # print(result['response'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts: 100%|██████████| 164/164 [38:19<00:00, 14.02s/it]\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"verifiers-for-code/humaneval_plan_generation\"\n",
    "results = process_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking>\n",
      "To generate a detailed plan for implementing the fix_spaces function, I need to break down the problem into clear, logical steps. The function needs to process a string, replace spaces with underscores, and handle consecutive spaces. The key aspects to consider are:\n",
      "\n",
      "1. Processing the input string\n",
      "2. Replacing spaces with underscores\n",
      "3. Handling consecutive spaces\n",
      "4. Returning the modified string\n",
      "\n",
      "I'll create a step-by-step plan that guides the implementation without providing the actual code. The plan will be detailed enough for a model to follow and implement the function correctly.\n",
      "</thinking>\n",
      "\n",
      "<plan>\n",
      "1. Process the input string:\n",
      "   - Store the input string in a variable (e.g., text)\n",
      "\n",
      "2. Replace spaces with underscores:\n",
      "   - Use the string method replace() to replace all spaces in the string with underscores\n",
      "   - Assign the result back to the text variable\n",
      "\n",
      "3. Handle consecutive spaces:\n",
      "   - Split the modified string into a list of substrings using the split() method\n",
      "   - Iterate through the list of substrings\n",
      "   - Check if the length of the current substring is greater than 2\n",
      "   - If true, replace the substring with a string containing a single underscore\n",
      "   - If false, keep the original substring\n",
      "   - Join the modified list of substrings back into a single string using the join() method\n",
      "\n",
      "4. Return the modified string:\n",
      "   - Return the final processed string\n",
      "\n",
      "Additional implementation details:\n",
      "- Use the appropriate string methods for replacing spaces, splitting, and joining strings\n",
      "- Ensure that the function handles empty input strings correctly\n",
      "- Consider using a more efficient approach for handling consecutive spaces, such as using a regular expression\n",
      "</plan>\n"
     ]
    }
   ],
   "source": [
    "print(results[-24][\"response\"][\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<thinking>\\nTo generate a detailed plan for implementing the has_close_elements function, I'll break down the problem into clear, logical steps. The function needs to check if any two numbers in the input list are closer to each other than a given threshold. The key aspects to consider are:\\n\\n1. Understanding the input parameters\\n2. Iterating through the list of numbers\\n3. Comparing each number with the rest of the list\\n4. Checking the distance between numbers and the threshold\\n5. Returning the result\\n\\nI'll create a step-by-step plan that guides the implementation without providing the actual code. The plan will be detailed enough for a model to follow and implement the function correctly.\\n</thinking>\\n\\n<plan>\\n1. Define the function with the required parameters:\\n   - `numbers`: a list of float numbers\\n   - `threshold`: a float number representing the minimum distance between two numbers\\n\\n2. Initialize a variable to store the result (default: False)\\n\\n3. Iterate through the list of numbers using a nested loop:\\n   a. For each number in the list, iterate through the rest of the list (from the next element to the end)\\n   b. Calculate the absolute difference between the current number and the other number\\n\\n4. Check if the absolute difference is less than the threshold:\\n   - If true, set the result variable to True and break the loop (exit early)\\n\\n5. After the loop, return the result:\\n   - If the result variable is True, it means there are two numbers closer than the threshold\\n   - If the result variable is False, it means no two numbers are closer than the threshold\\n\\nAdditional implementation details:\\n- Use a nested loop to compare each number with the rest of the list\\n- Use the absolute difference (abs() function) to compare the numbers\\n- Use a conditional statement (if) to check if the difference is less than the threshold\\n- Use a break statement to exit the loop early if a close pair is found\\n- Return a boolean value indicating whether any close pair was found\\n</plan>\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][\"response\"][\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi3_plans = [result[\"response\"][\"choices\"][0][\"message\"][\"content\"] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_COL_NAME = \"phi3-planner-granular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_id',\n",
       " 'prompt',\n",
       " 'canonical_solution',\n",
       " 'test',\n",
       " 'entry_point',\n",
       " 'sonnet-3.5_gold_plans',\n",
       " 'cleaned_sonnet-3.5_gold_plans',\n",
       " 'generated_phi3_baseline',\n",
       " 'generated_phi3_plan_generation',\n",
       " 'phi3-planner-plans',\n",
       " 'cleaned-phi3-planner-plans',\n",
       " 'self_planning_Phi-3-mini-4k-instruct',\n",
       " 'cleaned-self_planning_Phi-3-mini-4k-instruct',\n",
       " 'phi3-planner-granular']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "# Extract the 'test' split we worked with\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Create a list of the new column data\n",
    "phi3_plans = [result[\"response\"][\"choices\"][0][\"message\"][\"content\"] for result in results]\n",
    "\n",
    "# Add the new column to the dataset\n",
    "test_data = test_data.add_column(NEW_COL_NAME, phi3_plans)\n",
    "\n",
    "test_data.column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 56.93ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/verifiers-for-code/humaneval_plan_generation/commit/af2bb0cfd849e85ae9848a6d2d322f9fb7320f64', commit_message='Upload dataset', commit_description='', oid='af2bb0cfd849e85ae9848a6d2d322f9fb7320f64', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.push_to_hub(DATASET_NAME, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 936/936 [00:00<00:00, 4.19MB/s]\n",
      "Downloading data: 100%|██████████| 979k/979k [00:00<00:00, 4.22MB/s]\n",
      "Generating test split: 100%|██████████| 164/164 [00:00<00:00, 11555.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_id',\n",
       " 'prompt',\n",
       " 'canonical_solution',\n",
       " 'test',\n",
       " 'entry_point',\n",
       " 'sonnet-3.5_gold_plans',\n",
       " 'cleaned_sonnet-3.5_gold_plans',\n",
       " 'generated_phi3_baseline',\n",
       " 'generated_phi3_plan_generation',\n",
       " 'phi3-planner-plans',\n",
       " 'cleaned-phi3-planner-plans',\n",
       " 'self_planning_Phi-3-mini-4k-instruct',\n",
       " 'cleaned-self_planning_Phi-3-mini-4k-instruct',\n",
       " 'phi3-planner-granular']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
